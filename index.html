<!DOCTYPE html> 
<html> 
<head> 
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
<link rel="stylesheet" href="stylesheet.css">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>


<body style="background-color:rgba(0, 0, 0, 0.84);">
    <div class="flex-col">
        <h1 class="heading-text">ELT Pipeline: S&P 500</h1>
        <p class="intro-text"> The diagram below is updated every day to display the biggest growers and biggest losers among the 
            S&P 500 stocks for three different time periods relative to today: previous day, month, and year. More details and background
            on how this diagram is constructed is given below.
        </p>
    </div>
    <div class="flex-col">
    <div class="stocks_div">
    <iframe
    src="stocks_graph.html"
    style="width:100%; height:100%;"
    frameborder="0"
    allowtransparency
></iframe>
    </div>
    </div>
    <h2 class="heading-text" style="margin-top:15vh;">How It's Made</h2>
        <div class="image-container">
        <img src="images/ELTPIPELINE_image.jpg" style="max-width:100%;max-height:100%;">
        </div>
        <div class="main-body-text">
            <p style="text-align:center"> The provider for this data comes from the <a href="https://github.com/ranaroussi/yfinance">yfinance api</a></p>
            <p style="text-align:center"> This pipeline is automated with AWS services, taking advantage of the numerous free tier services provided by AWS. </p>
            <br>
            <p>Several python scripts were created and containerized with Docker, and then these container images were published to the Amazon Elastic Container Registry (AWS ECR) to create AWS lambda functions from them.</p>
            <p>A schedule was created with AWS EventBridge Scheduler that begins this pipeline everyday at 9:30pm EST by invoking an AWS lambda function. This lambda function then starts the AWS RDS postgresql database instance and publishes a message to an AWS SNS topic. The next lambda function in the sequence is subscribed to this topic and thus begins running once this message is recieved.</p>
            <p>The 2nd lambda function then extracts data from the yfinance api, parses this data to compute the biggest growers and losers, loads this data to the AWS RDS database, and publishes to a new SNS topic to begin the execution of the next lambda function.</p>
            <p> The 3rd lambda function connects to this database, uses this data to create the diagram above, and updates the github repo for this project with this new updated diagram.</p>
            <br>
            <p> The diagram above is created with the <a href="https://plotly.com/python/">Plotly</a> Python Library. This library can make very nice visuals, allows for easy data exports with offline html files, and it's free! I found it much more convenient to use this library as opposed to regular BI tools, which usually require a subscription in order to export/share visuals.</p>
            <p>The last AWS lambda function simply stops the database instance, so it remains inactive until the next pipeline execution cycle resumes it.</p>
        </div>
</body>
</html>